{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f11525",
   "metadata": {},
   "source": [
    "### Data Loading Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def toTensor(arr, long=False):     # utility function to convert numpy array to torch tensor\n",
    "    # Convert numpy array (possibly string-typed) to torch tensor\n",
    "    if arr.dtype.kind in {'U', 'S'}:  # string\n",
    "        arr = arr.astype(float)\n",
    "    if arr.shape == ():  # scalar\n",
    "        val = arr.item()\n",
    "        return torch.tensor(val, dtype=torch.long if long else torch.float32)\n",
    "    else:  # vector/array\n",
    "        return torch.tensor(arr, dtype=torch.long if long else torch.float32)\n",
    "\n",
    "\n",
    "class FacialDataset(Dataset):       # Custom Dataset class for facial images and annotations\n",
    "    def __init__(self, imgDir, anno_dir, img_size=224, transform=None):\n",
    "        self.img_dir = imgDir\n",
    "        self.anno_dir = anno_dir\n",
    "        self.transform = transform if transform else transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        # list all images\n",
    "        self.image_files = sorted([\n",
    "            f for f in os.listdir(imgDir) if f.endswith(\".jpg\")\n",
    "        ], key=lambda x: int(x.split(\".\")[0]))  # sort by numeric order\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):     # get item by index\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        base_id = os.path.splitext(img_name)[0]  # e.g. \"0\"\n",
    "        exp = np.load(os.path.join(self.anno_dir, f\"{base_id}_exp.npy\"))\n",
    "        val = np.load(os.path.join(self.anno_dir, f\"{base_id}_val.npy\"))\n",
    "        aro = np.load(os.path.join(self.anno_dir, f\"{base_id}_aro.npy\"))\n",
    "        lnd = np.load(os.path.join(self.anno_dir, f\"{base_id}_lnd.npy\"))\n",
    "\n",
    "        # conversions\n",
    "        exp_t = toTensor(exp, long=True)\n",
    "        val_t = toTensor(val)\n",
    "        aro_t = toTensor(aro)\n",
    "\n",
    "        lnd = lnd.astype(float).reshape(-1, 2)  # (68, 2)\n",
    "        lnd_t = torch.tensor(lnd, dtype=torch.float32)\n",
    "\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, exp_t, val_t, aro_t, lnd_t\n",
    "\n",
    "\n",
    "def getDataloader(root=\"Dataset\", batch_size=32, img_size=224, num_workers=0):     # utility function to create DataLoader\n",
    "    imgDir = os.path.join(root, \"images\")\n",
    "    annoDir = os.path.join(root, \"annotations\")\n",
    "    dataset = FacialDataset(imgDir, annoDir, img_size=img_size)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae35c417",
   "metadata": {},
   "source": [
    "### Architecture 1 - ConvNeXt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b2ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.0744, Train Acc=0.1594, Val Loss=2.0610, Val Acc=0.1625\n",
      "Model saved at epoch 1 with Val Acc=0.1625\n",
      "Epoch 2: Train Loss=2.0259, Train Acc=0.2088, Val Loss=2.0287, Val Acc=0.1975\n",
      "Model saved at epoch 2 with Val Acc=0.1975\n",
      "Epoch 3: Train Loss=1.9947, Train Acc=0.2398, Val Loss=2.0064, Val Acc=0.2150\n",
      "Model saved at epoch 3 with Val Acc=0.2150\n",
      "Epoch 4: Train Loss=1.9695, Train Acc=0.2523, Val Loss=1.9864, Val Acc=0.2225\n",
      "Model saved at epoch 4 with Val Acc=0.2225\n",
      "Epoch 5: Train Loss=1.9485, Train Acc=0.2651, Val Loss=1.9755, Val Acc=0.2288\n",
      "Model saved at epoch 5 with Val Acc=0.2288\n",
      "Backbone unfrozen – now fine-tuning full model\n",
      "Epoch 6: Train Loss=1.7942, Train Acc=0.3420, Val Loss=1.6495, Val Acc=0.3962\n",
      "Model saved at epoch 6 with Val Acc=0.3962\n",
      "Epoch 7: Train Loss=1.3939, Train Acc=0.5746, Val Loss=1.6181, Val Acc=0.4412\n",
      "Model saved at epoch 7 with Val Acc=0.4412\n",
      "Epoch 8: Train Loss=0.9980, Train Acc=0.7906, Val Loss=1.6427, Val Acc=0.4462\n",
      "Model saved at epoch 8 with Val Acc=0.4462\n",
      "Epoch 9: Train Loss=0.6886, Train Acc=0.9500, Val Loss=1.6758, Val Acc=0.4525\n",
      "Model saved at epoch 9 with Val Acc=0.4525\n",
      "Epoch 10: Train Loss=0.5720, Train Acc=0.9869, Val Loss=1.6984, Val Acc=0.4475\n",
      "Epoch 11: Train Loss=0.5397, Train Acc=0.9916, Val Loss=1.6837, Val Acc=0.4688\n",
      "Model saved at epoch 11 with Val Acc=0.4688\n",
      "Epoch 12: Train Loss=0.5217, Train Acc=0.9959, Val Loss=1.6773, Val Acc=0.4550\n",
      "Epoch 13: Train Loss=0.5104, Train Acc=0.9972, Val Loss=1.6647, Val Acc=0.4813\n",
      "Model saved at epoch 13 with Val Acc=0.4813\n",
      "Epoch 14: Train Loss=0.5086, Train Acc=0.9959, Val Loss=1.6945, Val Acc=0.4612\n",
      "Epoch 15: Train Loss=0.5047, Train Acc=0.9969, Val Loss=1.6971, Val Acc=0.4688\n",
      "Epoch 16: Train Loss=0.4993, Train Acc=0.9981, Val Loss=1.7292, Val Acc=0.4675\n",
      "Epoch 17: Train Loss=0.4931, Train Acc=0.9972, Val Loss=1.6953, Val Acc=0.4625\n",
      "Epoch 18: Train Loss=0.4883, Train Acc=0.9981, Val Loss=1.6796, Val Acc=0.4775\n",
      "Epoch 19: Train Loss=0.4867, Train Acc=0.9987, Val Loss=1.7214, Val Acc=0.4713\n",
      "Epoch 20: Train Loss=0.4846, Train Acc=0.9984, Val Loss=1.6866, Val Acc=0.4625\n",
      "Epoch 21: Train Loss=0.4831, Train Acc=0.9991, Val Loss=1.6831, Val Acc=0.4738\n",
      "Epoch 22: Train Loss=0.4822, Train Acc=0.9991, Val Loss=1.6829, Val Acc=0.4888\n",
      "Model saved at epoch 22 with Val Acc=0.4888\n",
      "Epoch 23: Train Loss=0.4812, Train Acc=0.9994, Val Loss=1.6810, Val Acc=0.4900\n",
      "Model saved at epoch 23 with Val Acc=0.4900\n",
      "Epoch 24: Train Loss=0.4801, Train Acc=0.9987, Val Loss=1.6808, Val Acc=0.4775\n",
      "Epoch 25: Train Loss=0.4806, Train Acc=0.9987, Val Loss=1.6868, Val Acc=0.4825\n",
      "Epoch 26: Train Loss=0.4791, Train Acc=0.9994, Val Loss=1.6937, Val Acc=0.4713\n",
      "Epoch 27: Train Loss=0.4797, Train Acc=0.9991, Val Loss=1.6923, Val Acc=0.4763\n",
      "Epoch 28: Train Loss=0.4787, Train Acc=0.9991, Val Loss=1.6885, Val Acc=0.4863\n",
      "Epoch 29: Train Loss=0.4778, Train Acc=0.9994, Val Loss=1.6860, Val Acc=0.4875\n",
      "Epoch 30: Train Loss=0.4792, Train Acc=0.9984, Val Loss=1.6890, Val Acc=0.4863\n"
     ]
    }
   ],
   "source": [
    "# ConvNeXt Training Pipeline \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "def getConvnextModel(num_classes, freezeBackbone=True):      # Load pre-trained ConvNeXt and modify for our task\n",
    "    model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1)    # load pre-trained ConvNeXt-Tiny\n",
    "\n",
    "    inFeatures = model.classifier[2].in_features\n",
    "    model.classifier[2] = nn.Linear(inFeatures, num_classes)\n",
    "\n",
    "    if freezeBackbone:  # freeze backbone at start\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    return model\n",
    "\n",
    "# Training function\n",
    "def trainModel(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=30, unfreezeEpoch=5):\n",
    "    bestValAcc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Unfreeze backbone after `unfreeze_epoch`\n",
    "        if epoch == unfreezeEpoch:\n",
    "            for param in model.features.parameters():\n",
    "                param.requires_grad = True\n",
    "            print(\"Backbone unfrozen – now fine-tuning full model\")\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        runningLoss, correct, total = 0.0, 0, 0\n",
    "        for imgs, exp, _, _, _ in train_loader:   # only using expression labels\n",
    "            imgs, exp = imgs.to(device), exp.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, exp)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runningLoss += loss.item() * imgs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(exp).sum().item()\n",
    "            total += exp.size(0)\n",
    "\n",
    "        trainLoss = runningLoss / total\n",
    "        trainAcc = correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        valLoss, valCorrect, valTotal = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, exp, _, _, _ in val_loader:\n",
    "                imgs, exp = imgs.to(device), exp.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, exp)\n",
    "\n",
    "                valLoss += loss.item() * imgs.size(0)\n",
    "                _, preds = outputs.max(1)\n",
    "                valCorrect += preds.eq(exp).sum().item()\n",
    "                valTotal += exp.size(0)\n",
    "\n",
    "        valLoss /= valTotal\n",
    "        valAcc = valCorrect / valTotal\n",
    "\n",
    "        scheduler.step(valAcc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={trainLoss:.4f}, Train Acc={trainAcc:.4f}, \"\n",
    "              f\"Val Loss={valLoss:.4f}, Val Acc={valAcc:.4f}\")\n",
    "        \n",
    "        # Save the model if validation accuracy improves\n",
    "        if valAcc > bestValAcc:\n",
    "            bestValAcc = valAcc\n",
    "            torch.save({\n",
    "                \"epoch\": epoch+1,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"val_acc\": valAcc\n",
    "            }, \"best_convnext.pth\")\n",
    "            print(f\"Model saved at epoch {epoch+1} with Val Acc={valAcc:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":      # Main execution block\n",
    "\n",
    "    trainTfms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  \n",
    "    transforms.ToTensor(),\n",
    "])      # Data augmentation for training\n",
    "\n",
    "    valTfms = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])      # Transformations for validation\n",
    "\n",
    "    # Load dataset \n",
    "    fullDataset = FacialDataset(\n",
    "        img_dir=\"Dataset/images\",\n",
    "        anno_dir=\"Dataset/annotations\",\n",
    "        img_size=224,\n",
    "        transform=None   \n",
    "    )\n",
    "\n",
    "    # Train/validation split (80/20)\n",
    "    trainSize = int(0.8 * len(fullDataset))\n",
    "    valSize = len(fullDataset) - trainSize\n",
    "    trainDataset, valDataset = random_split(fullDataset, [trainSize, valSize])\n",
    "\n",
    "    trainLoader = DataLoader(trainDataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    valLoader = DataLoader(valDataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    numClasses = 8\n",
    "    model = getConvnextModel(numClasses, freezeBackbone=True).to(device)    # load model\n",
    "\n",
    "    # Loss, optimizer, scheduler\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=5e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2)\n",
    "\n",
    "    # Train ConvNeXt\n",
    "    trainModel(model, trainLoader, valLoader, criterion, optimizer, scheduler, device,\n",
    "                num_epochs=30, unfreezeEpoch=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b52fa65",
   "metadata": {},
   "source": [
    "### Architecture 2 - EfficientNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660b744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to C:\\Users\\HP/.cache\\torch\\hub\\checkpoints\\efficientnet_v2_s-dd5fe13b.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82.7M/82.7M [00:37<00:00, 2.31MB/s]\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.0964, Train Acc=0.1357, Val Loss=2.0790, Val Acc=0.1500\n",
      "Model saved at epoch 1 with Val Acc=0.1500\n",
      "Epoch 2: Train Loss=2.0692, Train Acc=0.1694, Val Loss=2.0635, Val Acc=0.1737\n",
      "Model saved at epoch 2 with Val Acc=0.1737\n",
      "Epoch 3: Train Loss=2.0460, Train Acc=0.1841, Val Loss=2.0475, Val Acc=0.1913\n",
      "Model saved at epoch 3 with Val Acc=0.1913\n",
      "Epoch 4: Train Loss=2.0389, Train Acc=0.2066, Val Loss=2.0355, Val Acc=0.2150\n",
      "Model saved at epoch 4 with Val Acc=0.2150\n",
      "Epoch 5: Train Loss=2.0211, Train Acc=0.2191, Val Loss=2.0244, Val Acc=0.2137\n",
      "Backbone unfrozen – now fine-tuning full model\n",
      "Epoch 6: Train Loss=1.8740, Train Acc=0.3007, Val Loss=1.7473, Val Acc=0.3663\n",
      "Model saved at epoch 6 with Val Acc=0.3663\n",
      "Epoch 7: Train Loss=1.4864, Train Acc=0.5139, Val Loss=1.6690, Val Acc=0.4263\n",
      "Model saved at epoch 7 with Val Acc=0.4263\n",
      "Epoch 8: Train Loss=1.1102, Train Acc=0.7165, Val Loss=1.7795, Val Acc=0.4263\n",
      "Epoch 9: Train Loss=0.8019, Train Acc=0.8809, Val Loss=1.8811, Val Acc=0.4300\n",
      "Model saved at epoch 9 with Val Acc=0.4300\n",
      "Epoch 10: Train Loss=0.6483, Train Acc=0.9506, Val Loss=1.9587, Val Acc=0.4462\n",
      "Model saved at epoch 10 with Val Acc=0.4462\n",
      "Epoch 11: Train Loss=0.5890, Train Acc=0.9703, Val Loss=1.9607, Val Acc=0.4400\n",
      "Epoch 12: Train Loss=0.5826, Train Acc=0.9666, Val Loss=2.0310, Val Acc=0.4200\n",
      "Epoch 13: Train Loss=0.5588, Train Acc=0.9766, Val Loss=1.9923, Val Acc=0.4412\n",
      "Epoch 14: Train Loss=0.5413, Train Acc=0.9819, Val Loss=2.0440, Val Acc=0.4350\n",
      "Epoch 15: Train Loss=0.5222, Train Acc=0.9891, Val Loss=1.9988, Val Acc=0.4487\n",
      "Model saved at epoch 15 with Val Acc=0.4487\n",
      "Epoch 16: Train Loss=0.5186, Train Acc=0.9878, Val Loss=1.9974, Val Acc=0.4625\n",
      "Model saved at epoch 16 with Val Acc=0.4625\n",
      "Epoch 17: Train Loss=0.5091, Train Acc=0.9906, Val Loss=2.0743, Val Acc=0.4400\n",
      "Epoch 18: Train Loss=0.5056, Train Acc=0.9934, Val Loss=2.0220, Val Acc=0.4600\n",
      "Epoch 19: Train Loss=0.4982, Train Acc=0.9950, Val Loss=2.0517, Val Acc=0.4600\n",
      "Epoch 20: Train Loss=0.4978, Train Acc=0.9944, Val Loss=2.0734, Val Acc=0.4363\n",
      "Epoch 21: Train Loss=0.4910, Train Acc=0.9975, Val Loss=2.0700, Val Acc=0.4437\n",
      "Epoch 22: Train Loss=0.4907, Train Acc=0.9972, Val Loss=2.0506, Val Acc=0.4462\n",
      "Epoch 23: Train Loss=0.4913, Train Acc=0.9972, Val Loss=2.0769, Val Acc=0.4575\n",
      "Epoch 24: Train Loss=0.4883, Train Acc=0.9981, Val Loss=2.0644, Val Acc=0.4525\n",
      "Epoch 25: Train Loss=0.4891, Train Acc=0.9972, Val Loss=2.0666, Val Acc=0.4475\n",
      "Epoch 26: Train Loss=0.4890, Train Acc=0.9966, Val Loss=2.0520, Val Acc=0.4525\n",
      "Epoch 27: Train Loss=0.4877, Train Acc=0.9978, Val Loss=2.0582, Val Acc=0.4562\n",
      "Epoch 28: Train Loss=0.4877, Train Acc=0.9987, Val Loss=2.0625, Val Acc=0.4637\n",
      "Model saved at epoch 28 with Val Acc=0.4637\n",
      "Epoch 29: Train Loss=0.4870, Train Acc=0.9969, Val Loss=2.0682, Val Acc=0.4537\n",
      "Epoch 30: Train Loss=0.4879, Train Acc=0.9969, Val Loss=2.0637, Val Acc=0.4637\n"
     ]
    }
   ],
   "source": [
    "# EfficientNetV2 Training Pipeline \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Model definition\n",
    "def getEfficientnetv2Model(num_classes, freezeBackbone=True):\n",
    "    model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
    "    inFeatures = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(inFeatures, num_classes)\n",
    "    )\n",
    "    if freezeBackbone:\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "    return model\n",
    "\n",
    "# Training loop\n",
    "def trainModel(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=30, unfreeze_epoch=5):\n",
    "    bestValAcc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch == unfreeze_epoch:\n",
    "            for param in model.features.parameters():       # unfreeze backbone\n",
    "                param.requires_grad = True\n",
    "            print(\"Backbone unfrozen – now fine-tuning full model\")\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        runningLoss, correct, total = 0.0, 0, 0\n",
    "        for imgs, exp, _, _, _ in train_loader:     # only using expression labels\n",
    "            imgs, exp = imgs.to(device), exp.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, exp)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            runningLoss += loss.item() * imgs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(exp).sum().item()\n",
    "            total += exp.size(0)\n",
    "\n",
    "        trainLoss = runningLoss / total\n",
    "        trainAcc = correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()        # evaluate mode\n",
    "        valLoss, valCorrect, valTotal = 0.0, 0, 0\n",
    "        with torch.no_grad():       # no gradient computation\n",
    "            for imgs, exp, _, _, _ in val_loader:\n",
    "                imgs, exp = imgs.to(device), exp.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, exp)\n",
    "                valLoss += loss.item() * imgs.size(0)\n",
    "                _, preds = outputs.max(1)\n",
    "                valCorrect += preds.eq(exp).sum().item()\n",
    "                valTotal += exp.size(0)\n",
    "\n",
    "        valLoss /= valTotal\n",
    "        valAcc = valCorrect / valTotal\n",
    "        scheduler.step(valAcc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={trainLoss:.4f}, Train Acc={trainAcc:.4f}, \"\n",
    "              f\"Val Loss={valLoss:.4f}, Val Acc={valAcc:.4f}\")\n",
    "\n",
    "        if valAcc > bestValAcc:\n",
    "            bestValAcc = valAcc\n",
    "            torch.save(model.state_dict(), \"efficientnetv2_best.pth\")\n",
    "            print(f\"Model saved at epoch {epoch+1} with Val Acc={valAcc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset from the data loading pipeline\n",
    "    fullDataset = FacialDataset(\n",
    "        img_dir=\"Dataset/images\",\n",
    "        anno_dir=\"Dataset/annotations\",\n",
    "        img_size=224,\n",
    "        transform=None   \n",
    "    )\n",
    "\n",
    "    # Train/validation split\n",
    "    trainSize = int(0.8 * len(fullDataset))       \n",
    "    valSize = len(fullDataset) - trainSize\n",
    "    trainDataset, valDataset = random_split(fullDataset, [trainSize, valSize])\n",
    "    trainLoader = DataLoader(trainDataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    valLoader = DataLoader(valDataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    numClasses = 8\n",
    "    model = getEfficientnetv2Model(numClasses, freezeBackbone=True).to(device)      # load model\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=5e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=3)\n",
    "\n",
    "    trainModel(model, trainLoader, valLoader, criterion, optimizer, scheduler, device,\n",
    "                num_epochs=30, unfreeze_epoch=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
